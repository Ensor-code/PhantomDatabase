{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from elasticsearch import helpers  # For bulk Data Uploading\n",
    "from elasticsearch import Elasticsearch  # Base function for interacting with Elasticsearch\n",
    "from elasticsearch import RequestError\n",
    "from pprint import pprint\n",
    "from load_func import *\n",
    "\n",
    "# remove excessive HTTPS request warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elastic search \n",
    "This is done using your own API key, generated using kibana, which should be stored localy on your machine. We stored our API key in a .env file in the same folder as this script, and use the python module dotenv to load it as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'alhena.ster.kuleuven.be', 'cluster_name': 'elasticsearch', 'cluster_uuid': '9KoZG2x-QPS21BzKMnLzqw', 'version': {'number': '8.15.3', 'build_flavor': 'default', 'build_type': 'tar', 'build_hash': 'f97532e680b555c3a05e73a74c28afb666923018', 'build_date': '2024-10-09T22:08:00.328917561Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/elasticsearch/_sync/client/__init__.py:400: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "client = Elasticsearch(\"https://localhost:9200/\", api_key=os.getenv('API_KEY'),verify_certs=False)\n",
    "\n",
    "#test client\n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionnaries containing all the mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the mappings list from the metadata.csv file, which is generated externally from the shared excel file, and the list is then transformed into a dictionnary of mappings with the proper formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab mappings list from the csv file, which should be in the same directory as the script\n",
    "DIR_NAME = os.getcwd()\n",
    "FILE_NAME = \"metadata.csv\"\n",
    "FILE_PATH = os.path.join(DIR_NAME, FILE_NAME)\n",
    "data, header = read_csv(FILE_PATH)\n",
    "# index name\n",
    "INDEX_NAME = \"wind\"\n",
    "\n",
    "# indicate if you want to update existing documents\n",
    "UPDATE = False\n",
    "\n",
    "# create the dictionnary of mappings\n",
    "mappings = create_mapping(data, header)\n",
    "#pprint(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add other settings to the index parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"settings\" is technically not needed if we are working on a simple local host, but can be changed to optimise search performance on a database that is hosted on a cluster and searched by multiple users.\n",
    "\"mappings\" is required if you wish to explicitly map fields to specific values\n",
    "\"\"\"\n",
    "\n",
    "index_definition = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "    },\n",
    "    \"mappings\": {\"properties\": mappings},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the index using the parameters set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/539rkvgx2mb6prc2mcx2djxmdpkh7p/T/ipykernel_2217/356881687.py:3: ElasticsearchWarning: this request accesses system indices: [.kibana_ingest_8.15.3_001, .kibana_security_session_1, .apm-custom-link, .kibana_8.15.3_001, .kibana_task_manager_8.15.3_001, .security-profile-8, .apm-agent-configuration, .kibana_analytics_8.15.3_001, .security-7, .kibana_alerting_cases_8.15.3_001, .kibana_security_solution_8.15.3_001, .async-search], but in a future major version, direct access to system indices will be prevented by default\n",
      "  if INDEX_NAME in client.indices.get_alias(index=\"*\"):\n"
     ]
    }
   ],
   "source": [
    "\"\"\" create index if it does not exist \"\"\"\n",
    "\n",
    "if INDEX_NAME in client.indices.get_alias(index=\"*\"):\n",
    "    print(\"Index already exists, delete it if you want to recreate it\")\n",
    "else:\n",
    "    client.indices.create(index=INDEX_NAME, body=index_definition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kibana\n",
    "\n",
    "Once the index is created in elasticsearch, in order to view it in Kibana, go to **Management** and on left menu bar, scroll down to the **Kibana** subsection, and click **Data Views**. From here, on the top right, click **Create data view** in order to integrate the new index into the Kibana interface. This will allow you to view how kibana interprets the index you have created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "Now that the index is created and visible in Kibana, we can start mapping models to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories and file names here\n",
    "DIR = \"/Users/camille/Documents/runs/phantom/database/wind\"  # Careful, this is a local path - change it to your own\n",
    "PREFIX = \"wind\"\n",
    "\n",
    "# read model list from external file\n",
    "list_dir = \"/Users/camille/Documents/PhantomDatabase/\"\n",
    "list_name = \"model_list.txt\"\n",
    "MODELS = read_model_list(os.path.join(list_dir, list_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load information from .setup and .in file\n",
    "We can upload Documents of interest by indexing them using the parameters in their data files, for instance .setup and .in files. We can load multiple models at a time, which is preferable of course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /Users/camille/Documents/runs/phantom/database/wind/icompstar_2_subst_11_m1_1.6_aIn_5.0_eIn_0.0_m2_0.4_racc2_0.04_a_35.0_e_0.3_incl_0.0_gamma_1.2_m3_1.5_racc3_0.04_eos_2_mu_2.381_icooling_1_icoolmeth_0_HIexcit_1_Tfloor_0.0_f_acc_0.8_vw_15.0_Rinj_1.2_mlr_1.1e-06_Tw_1500.0_iwr_4_wss_0.8_bound_1500.0 No wind_1D.data or windprofile1D.dat file found! Some wind data will be missing -\n",
      "Warning: /Users/camille/Documents/runs/phantom/database/wind/m1_1.5_icompstar_1_m2_1.0_racc2_0.01_a_6.0_e_0.0_gamma_1.2_eos_2_mu_2.381_icooling_1_icoolmeth_0_HIexcit_1_Tfloor_0.0_f_acc_0.8_vw_5.0_Rinj_1.3_mlr_1e-07_Tw_3000.0_iwr_5_wss_1.0_bound_250.0 No wind_1D.data or windprofile1D.dat file found! Some wind data will be missing -\n",
      "Warning: /Users/camille/Documents/runs/phantom/database/wind/m1_1.5_icompstar_1_m2_1.0_racc2_0.05_a_6.0_e_0.0_gamma_1.2_eos_2_mu_2.381_icooling_0_f_acc_0.8_vw_10.0_Rinj_1.3_mlr_1e-06_Tw_1500.0_iwr_5_wss_0.65_bound_200.0 No wind_1D.data or windprofile1D.dat file found! Some wind data will be missing -\n",
      "Warning: /Users/camille/Documents/runs/phantom/database/wind/m1_1.6_icompstar_1_m2_1.06_racc2_0.05_a_125.0_e_0.92_gamma_1.2_eos_2_mu_2.381_icooling_0_f_acc_0.8_vw_13.0_Rinj_2.0_mlr_5e-05_Tw_1500.0_iwr_3_wss_1.2_bound_50000.0 No wind_1D.data or windprofile1D.dat file found! Some wind data will be missing -\n",
      "All 339 documents will be uploaded.\n"
     ]
    }
   ],
   "source": [
    "# Generate the operations list to upload multiple documents\n",
    "\n",
    "operations = []\n",
    "update_count = 0\n",
    "skip_count = 0\n",
    "for model in MODELS:\n",
    "    base_command = {\"_index\": INDEX_NAME, \"_op_type\": \"index\"}\n",
    "    # check if document already exists\n",
    "    id = query_document(client, INDEX_NAME,model)\n",
    "\n",
    "    # check if existing document should be updated\n",
    "    if id and UPDATE:\n",
    "        # delete and reupload\n",
    "        update_count += 1\n",
    "        client.delete(index=INDEX_NAME, id=id)\n",
    "    elif id and not UPDATE:\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    # load data\n",
    "    modelData = LoadDoc(DIR, model, PREFIX, index_definition)\n",
    "    # check that all the entries are correctly filled\n",
    "    CheckEntries(model,modelData)\n",
    "    operations.append((base_command | {\"_source\": modelData}))\n",
    "\n",
    "if UPDATE and update_count>0 : print(f'{update_count}/{len(MODELS)} documents already exist and will be updated.')\n",
    "elif skip_count>0: print(f'{skip_count}/{len(MODELS)} documents already exist and will be skipped.')\n",
    "else: print(f'All {len(MODELS)} documents will be uploaded.')\n",
    "#pprint(operations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, [])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the documents\n",
    "helpers.bulk(client, operations, refresh=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
