{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from elasticsearch import helpers  # For bulk Data Uploading\n",
    "from elasticsearch import Elasticsearch  # Base function for interacting with Elasticsearch\n",
    "from elasticsearch import RequestError\n",
    "from pprint import pprint\n",
    "from load_ini import *\n",
    "\n",
    "# remove excessive HTTPS request warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elastic search \n",
    "This is done using your own API key, generated using kibana, which should be stored localy on your machine. We stored our API key in a .env file in the same folder as this script, and use the python module dotenv to load it as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'alhena.ster.kuleuven.be', 'cluster_name': 'elasticsearch', 'cluster_uuid': '9KoZG2x-QPS21BzKMnLzqw', 'version': {'number': '8.15.3', 'build_flavor': 'default', 'build_type': 'tar', 'build_hash': 'f97532e680b555c3a05e73a74c28afb666923018', 'build_date': '2024-10-09T22:08:00.328917561Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/elasticsearch/_sync/client/__init__.py:400: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "client = Elasticsearch(\"https://localhost:9200/\", api_key=os.getenv('API_KEY'),verify_certs=False)\n",
    "\n",
    "#test client\n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionnaries containing all the mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the mappings list from the metadata.csv file, which is generated externally from the shared excel file, and the list is then transformed into a dictionnary of mappings with the proper formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model name': {'type': 'keyword'},\n",
      " 'Publication/reference': {'type': 'keyword'},\n",
      " 'Tfloor': {'meta': {'file': '.in'}, 'type': 'float'},\n",
      " 'alpha_rad': {'meta': {'file': '.in'}, 'type': 'float'},\n",
      " 'binary2_a': {'meta': {'file': '.setup'}, 'type': 'float'},\n",
      " 'binary2_e': {'meta': {'file': '.setup'}, 'type': 'float'},\n",
      " 'eccentricity': {'meta': {'file': '.setup'}, 'type': 'float'},\n",
      " 'excitation_HI': {'meta': {'file': '.in'}, 'type': 'integer'},\n",
      " 'f_acc': {'meta': {'file': '.in'}, 'type': 'float'},\n",
      " 'icompanion_star': {'meta': {'file': '.setup'}, 'type': 'integer'},\n",
      " 'icool_method': {'meta': {'file': '.in'}, 'type': 'integer'},\n",
      " 'icooling': {'meta': {'file': '.in'}, 'type': 'integer'},\n",
      " 'idust_opacity': {'meta': {'file': '.in'}, 'type': 'integer'},\n",
      " 'ieos': {'meta': {'file': '.in'}, 'type': 'integer'},\n",
      " 'iget_tdust': {'meta': {'file': '.in'}, 'type': 'integer'},\n",
      " 'inclination': {'meta': {'file': '.setup'}, 'type': 'float'},\n",
      " 'isink_radiation': {'meta': {'file': '.in'}, 'type': 'integer'},\n",
      " 'iwind_resolution': {'meta': {'file': '.in'}, 'type': 'integer'},\n",
      " 'mass_ratio': {'type': 'float'},\n",
      " 'model date': {'meta': {'file': 'header.txt'}, 'type': 'keyword'},\n",
      " 'mu': {'meta': {'file': '.in'}, 'type': 'float'},\n",
      " 'outer_boundary': {'meta': {'file': '.in', 'units': 'au'}, 'type': 'float'},\n",
      " 'particle mass': {'meta': {'file': 'header.txt', 'units': 'Msol'},\n",
      "                   'type': 'float'},\n",
      " 'path to folder': {'type': 'keyword'},\n",
      " 'period': {'meta': {'units': 'd'}, 'type': 'float'},\n",
      " 'primary_Reff': {'meta': {'file': '.setup', 'units': 'Rsol'}, 'type': 'float'},\n",
      " 'primary_Teff': {'meta': {'file': '.setup', 'units': 'K'}, 'type': 'float'},\n",
      " 'primary_mass': {'meta': {'file': '.setup', 'units': 'Msol'}, 'type': 'float'},\n",
      " 'primary_racc': {'meta': {'file': '.setup', 'units': 'Rsol'}, 'type': 'float'},\n",
      " 'resolution (current)': {'meta': {'file': 'header.txt'}, 'type': 'integer'},\n",
      " 'secondary_Reff': {'meta': {'file': '.setup', 'units': 'Rsol'},\n",
      "                    'type': 'float'},\n",
      " 'secondary_Teff': {'meta': {'file': '.setup', 'units': 'K'}, 'type': 'float'},\n",
      " 'secondary_mass': {'meta': {'file': '.setup', 'units': 'Msol'},\n",
      "                    'type': 'float'},\n",
      " 'secondary_racc': {'meta': {'file': '.setup', 'units': 'Rsol'},\n",
      "                    'type': 'float'},\n",
      " 'semi_major_axis': {'meta': {'file': '.setup', 'units': 'au'},\n",
      "                     'type': 'float'},\n",
      " 'simulation time': {'meta': {'file': '.ev', 'units': 's'}, 'type': 'float'},\n",
      " 'subst': {'meta': {'file': '.setup'}, 'type': 'integer'},\n",
      " 'tertiary_Reff': {'meta': {'file': '.setup', 'units': 'Rsol'},\n",
      "                   'type': 'float'},\n",
      " 'tertiary_Teff': {'meta': {'file': '.setup', 'units': 'K'}, 'type': 'float'},\n",
      " 'tertiary_mass': {'meta': {'file': '.setup', 'units': 'Msol'},\n",
      "                   'type': 'float'},\n",
      " 'tertiary_racc': {'meta': {'file': '.setup', 'units': 'Rsol'},\n",
      "                   'type': 'float'},\n",
      " 'version': {'meta': {'file': 'header.txt'}, 'type': 'keyword'},\n",
      " 'wind_gamma': {'meta': {'file': '.setup'}, 'type': 'float'},\n",
      " 'wind_inject_radius': {'meta': {'file': '.in', 'units': 'au'},\n",
      "                        'type': 'float'},\n",
      " 'wind_mass_rate': {'meta': {'file': '.in', 'units': 'Msol/yr'},\n",
      "                    'type': 'float'},\n",
      " 'wind_shell_spacing': {'meta': {'file': '.in'}, 'type': 'float'},\n",
      " 'wind_temperature': {'meta': {'file': '.in', 'units': 'K'}, 'type': 'float'},\n",
      " 'wind_terminal_velocity': {'meta': {'file': 'wind_1D.dat', 'units': 'km/s'},\n",
      "                            'type': 'float'},\n",
      " 'wind_velocity': {'meta': {'file': '.in', 'units': 'km/s'}, 'type': 'float'}}\n"
     ]
    }
   ],
   "source": [
    "# grab mappings list from the csv file, which should be in the same directory as the script\n",
    "DIR_NAME = os.getcwd()\n",
    "FILE_NAME = \"metadata.csv\"\n",
    "FILE_PATH = os.path.join(DIR_NAME, FILE_NAME)\n",
    "data, header = read_csv(FILE_PATH)\n",
    "\n",
    "# index name\n",
    "INDEX_NAME = \"wind\"\n",
    "\n",
    "# indicate if you want to update existing documents\n",
    "UPDATE = True\n",
    "\n",
    "# create the dictionnary of mappings\n",
    "mappings = create_mapping(data, header)\n",
    "pprint(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add other settings to the index parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"settings\" is technically not needed if we are working on a simple local host, but can be changed to optimise search performance on a database that is hosted on a cluster and searched by multiple users.\n",
    "\"mappings\" is required if you wish to explicitly map fields to specific values\n",
    "\"\"\"\n",
    "\n",
    "index_definition = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "    },\n",
    "    \"mappings\": {\"properties\": mappings},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the index using the parameters set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists, delete it if you want to recreate it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/539rkvgx2mb6prc2mcx2djxmdpkh7p/T/ipykernel_21293/356881687.py:3: ElasticsearchWarning: this request accesses system indices: [.kibana_ingest_8.15.3_001, .kibana_security_session_1, .apm-custom-link, .kibana_8.15.3_001, .kibana_task_manager_8.15.3_001, .security-profile-8, .apm-agent-configuration, .kibana_analytics_8.15.3_001, .security-7, .kibana_alerting_cases_8.15.3_001, .kibana_security_solution_8.15.3_001, .async-search], but in a future major version, direct access to system indices will be prevented by default\n",
      "  if INDEX_NAME in client.indices.get_alias(index=\"*\"):\n"
     ]
    }
   ],
   "source": [
    "\"\"\" create index if it does not exist \"\"\"\n",
    "\n",
    "if INDEX_NAME in client.indices.get_alias(index=\"*\"):\n",
    "    print(\"Index already exists, delete it if you want to recreate it\")\n",
    "else:\n",
    "    client.indices.create(index=INDEX_NAME, body=index_definition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kibana\n",
    "\n",
    "Once the index is created in elasticsearch, in order to view it in Kibana, go to **Management** and on left menu bar, scroll down to the **Kibana** subsection, and click **Data Views**. From here, on the top right, click **Create data view** in order to integrate the new index into the Kibana interface. This will allow you to view how kibana interprets the index you have created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "Now that the index is created and visible in Kibana, we can start mapping models to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories and file names here\n",
    "DIR = \"/Users/camille/Documents/runs/phantom/database/wind\"  # Careful, this is a local path - change it to your own\n",
    "PREFIX = \"wind\"\n",
    "\n",
    "# read model list from external file\n",
    "list_dir = \"/Users/camille/Documents/PhantomDatabase/\"\n",
    "list_name = \"model_list.txt\"\n",
    "MODELS = read_model_list(os.path.join(list_dir, list_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load information from .setup and .in file\n",
    "We can upload Documents of interest by indexing them using the parameters in their data files, for instance .setup and .in files. We can load multiple models at a time, which is preferable of course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /Users/camille/Documents/runs/phantom/database/wind/icompstar_2_subst_11_m1_1.6_aIn_5.0_eIn_0.0_m2_0.4_racc2_0.04_a_35.0_e_0.3_gamma_1.2_m3_1.5_racc3_0.04_eos_2_mu_2.381_icooling_1_icoolmeth_0_HIexcit_1_Tfloor_0.0_f_acc_0.8_vw_15.0_Rinj_1.2_mlr_1.1e-06_Tw_1500.0_iwr_4_wss_0.8_bound_1500.0 No wind_1D.data or windprofile1D.dat file found! Some wind data will be missing -\n",
      "Warning: /Users/camille/Documents/runs/phantom/database/wind/m1_1.5_m2_1.0_racc2_0.01_a_6.0_e_0.0_gamma_1.2_eos_2_mu_2.381_icooling_1_icoolmeth_0_HIexcit_1_Tfloor_0.0_f_acc_0.8_vw_5.0_Rinj_1.3_mlr_1e-07_Tw_3000.0_iwr_5_wss_1.0_bound_250.0 No wind_1D.data or windprofile1D.dat file found! Some wind data will be missing -\n",
      "Warning: /Users/camille/Documents/runs/phantom/database/wind/m1_1.5_m2_1.0_racc2_0.05_a_6.0_e_0.0_gamma_1.2_eos_2_mu_2.381_icooling_0_f_acc_0.8_vw_10.0_Rinj_1.3_mlr_1e-06_Tw_1500.0_iwr_5_wss_0.65_bound_200.0 No wind_1D.data or windprofile1D.dat file found! Some wind data will be missing -\n",
      "Warning: /Users/camille/Documents/runs/phantom/database/wind/m1_1.6_m2_1.06_racc2_0.05_a_125.0_e_0.92_gamma_1.2_eos_2_mu_2.381_icooling_0_f_acc_0.8_vw_13.0_Rinj_2.0_mlr_5e-05_Tw_1500.0_iwr_3_wss_1.2_bound_50000.0 No wind_1D.data or windprofile1D.dat file found! Some wind data will be missing -\n",
      "343/148 documents already exist,{update_count} documents will be updated,{skip_count} documents will be skipped\n"
     ]
    }
   ],
   "source": [
    "# Generate the operations list to upload multiple documents\n",
    "\n",
    "operations = []\n",
    "update_count = 0\n",
    "skip_count = 0\n",
    "for model in MODELS:\n",
    "    base_command = {\"_index\": INDEX_NAME, \"_op_type\": \"index\"}\n",
    "\n",
    "    # check if document already exists\n",
    "    id = query_document(client, INDEX_NAME,model)\n",
    "\n",
    "    # check if existing document should be updated\n",
    "    if id and UPDATE:\n",
    "        # delete and reupload\n",
    "        update_count += 1\n",
    "        client.delete(index=INDEX_NAME, id=id)\n",
    "    elif id and not UPDATE:\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    # load data\n",
    "    modelData = LoadDoc(DIR, model, PREFIX, index_definition)\n",
    "    # check that all the entries are correctly filled\n",
    "    CheckEntries(model,modelData)\n",
    "    operations.append((base_command | {\"_source\": modelData}))\n",
    "\n",
    "if UPDATE: print(f'{update_count}/{len(MODELS)} documents already exist and will be updated.')\n",
    "else: print(f'{skip_count}/{len(MODELS)} documents already exist and will be skipped.')\n",
    "#pprint(operations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the documents\n",
    "helpers.bulk(client, operations, refresh=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now look into Dashboards: Analytics - Dashboards to visualise data\n",
    "Documentation: https://www.elastic.co/guide/en/kibana/current/create-a-dashboard-of-panels-with-web-server-data.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
